{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "k_13ZnfacaqJ",
        "JKAE5ExJ5CwI",
        "1nR3rG-AwXcz"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install -qqq langchain langchain-community"
      ],
      "metadata": {
        "id": "xDSe8iwblPl-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "de8_PTMRccna"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Ingestion (PDF)"
      ],
      "metadata": {
        "id": "k_13ZnfacaqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[langchain_concept_document_loaders](https://python.langchain.com/docs/integrations/document_loaders/)"
      ],
      "metadata": {
        "id": "L6KWmF6EnBg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -qqq pymupdf"
      ],
      "metadata": {
        "id": "oU2XTphwcmyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loading & Extract\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "loader = PyMuPDFLoader('example_pdf')\n",
        "\n",
        "docs = loader.load() # -> List[Document] : returns a list of Document objects"
      ],
      "metadata": {
        "id": "xLAqlEvqYRf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## without Langchain"
      ],
      "metadata": {
        "id": "rQ6-8s0UdVQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "\n",
        "# pdf load\n",
        "pdf = fitz.open('example.pdf')\n",
        "\n",
        "# single page extract\n",
        "def extract_single_page(pdf, pdf_num=0):\n",
        "    page = pdf.load_page(pdf_num)\n",
        "    text = page.get_text(\"text\")  # Extract text from pdf\n",
        "    return text\n",
        "\n",
        "def extract_all_page(pdf):\n",
        "    all_text = \"\"\n",
        "    for page_num in range(pdf.page_count):\n",
        "        all_text += extract_single_page(pdf, page_num)\n",
        "    return all_text\n",
        "\n",
        "pdf.close()"
      ],
      "metadata": {
        "id": "OZz9jgx0c6tC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with fitz.open('example.pdf') as pdf:\n",
        "    text = extract_all_page(pdf)"
      ],
      "metadata": {
        "id": "I_E8_C4DiT2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "검색된 결과는 최종적으로 LLM의 프롬프트에 query와 함께 입력되기 때문에 **text**로 추출하여 저장하게 됩니다.\n",
        "\n",
        "그러나 langchain에서는 검색된 문서의 정보(metadata)를 효과적으로 관리하고 활용하기 위해서 **Document**객체로 wrapping하여 사용하고있습니다."
      ],
      "metadata": {
        "id": "Z4SpzvYYj7yy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Indexing"
      ],
      "metadata": {
        "id": "7204SOn2sG_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splitting & Chinking\n",
        "\n",
        "[langchain_concept_text_splitter](https://python.langchain.com/docs/concepts/text_splitters/)"
      ],
      "metadata": {
        "id": "JKAE5ExJ5CwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install -qU langchain-text-splitters"
      ],
      "metadata": {
        "id": "ytt9SmJGqYCZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
        "\n",
        "texts = text_splitter.split_text(example_documents)"
      ],
      "metadata": {
        "id": "lLcg9tA9jiYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "langchain의 TextSplitter의 methods\n",
        "1. split_text :\n",
        "    split_text(text: str) -> List[str]\n",
        "\n",
        "    텍스트를 input으로 받아, 조건에 맞춰 text로 split해주는 함수\n",
        "\n",
        "2. create_documents :\n",
        "    create_documents(texts: list[str], metadatas: Optional[list[dict[Any, Any]]]) -> List[Document]\n",
        "\n",
        "    str List와 metadata로 Document객체를 만드는 함수\n",
        "\n",
        "3. split_documents :\n",
        "    split_documents(documents: Iterable[Document]) -> List[Document]\n",
        "\n",
        "    Document객체를 input으로 받아, 조건에 맞춰 Document객체로 split해주는 함수\n",
        "'''"
      ],
      "metadata": {
        "id": "AEB55XTIqy7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## without Langchain"
      ],
      "metadata": {
        "id": "1nR3rG-AwXcz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### plain text splitter"
      ],
      "metadata": {
        "id": "95U0nyVO4S2F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plain_text_split(all_text, chunk_size, overlap):\n",
        "    chunks = []\n",
        "\n",
        "    for chunck_start in range(0, len(all_text), chunk_size - overlap):\n",
        "        chunk = all_text[chunck_start : chunck_start + chunk_size]\n",
        "        chunks.append(chunk)\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "Uj3CCrYLvo4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple Recursive Splitter"
      ],
      "metadata": {
        "id": "EOYYWOe-4K8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recursive_split(text, chunk_size, separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]):\n",
        "    sep = separators[0]\n",
        "    parts = text.split(sep)\n",
        "    chunks = []\n",
        "    current_chunk = \"\"\n",
        "\n",
        "    for part in parts:\n",
        "        if len(current_chunk) + len(part) <= chunk_size:\n",
        "            current_chunk += part\n",
        "        else:\n",
        "            if current_chunk:\n",
        "                chunks.append(current_chunk.strip())\n",
        "            if len(part) > chunk_size and len(separators) > 1:\n",
        "                chunks.extend(recursive_split(part, separators[1:]))\n",
        "            else:\n",
        "                chunks.append(part.strip())\n",
        "            current_chunk = \"\"\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk.strip())\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "R7NG-nJK0pZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_with_overlap(chunks, chunk_size, overlap):\n",
        "    merged = []\n",
        "    i = 0\n",
        "    while i < len(chunks):\n",
        "        chunk = chunks[i]\n",
        "        current = chunk\n",
        "        i += 1\n",
        "        while i < len(chunks) and len(current) + len(chunks[i]) <= chunk_size:\n",
        "            current += \" \" + chunks[i]\n",
        "            i += 1\n",
        "        merged.append(current.strip())\n",
        "\n",
        "    # overlap 처리\n",
        "    final_chunks = []\n",
        "    for chunk in merged:\n",
        "        if not final_chunks:\n",
        "            final_chunks.append(chunk)\n",
        "        else:\n",
        "            prev = final_chunks[-1]\n",
        "            overlap = prev[-overlap :] if overlap < len(prev) else prev\n",
        "            combined = overlap + \" \" + chunk\n",
        "            final_chunks.append(combined.strip())\n",
        "    return final_chunks"
      ],
      "metadata": {
        "id": "0zCRmpNg2fjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_recursive_splitter(text, chunk_size, overlap):\n",
        "    chunks = recursive_split(text, chunk_size)  # List[chunk]\n",
        "    return merge_with_overlap(chunks, chunk_size, overlap)"
      ],
      "metadata": {
        "id": "dU10a_iP3L_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Creation"
      ],
      "metadata": {
        "id": "PK4d4eln48N8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -qqq langchain-openai"
      ],
      "metadata": {
        "id": "IPkaIqhf4_vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "import os\n",
        "EMB_MODEL_NAME=\"text-embedding-3-small\"\n",
        "api_key=os.getenv(\"OPENAI_API_KEY\")\n",
        "embeddings = OpenAIEmbeddings(model=EMB_MODEL_NAME, api_key=api_key)"
      ],
      "metadata": {
        "id": "GBec_-7H6XGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"TEST embedding text\"\n",
        "query_result = embeddings.embed_query(text)\n",
        "\n",
        "# document embedding\n",
        "doc_result = embeddings.embed_documents(docs)"
      ],
      "metadata": {
        "id": "6a--v7SS7Jha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding dimension config\n",
        "embeddings_1024 = OpenAIEmbeddings(model=EMB_MODEL_NAME, api_key=api_key, dimensions=1024)"
      ],
      "metadata": {
        "id": "8qtTq99j7zVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VectorStore"
      ],
      "metadata": {
        "id": "SHmKxDNQ8Zzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FAISS"
      ],
      "metadata": {
        "id": "jonZOx7W8vRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "\n",
        "dimension_size = len(embeddings.embed_query(\"hello world\"))\n",
        "\n",
        "# langchain vector db init 방식 (1)\n",
        "faiss_vector_db = FAISS(\n",
        "    embedding_function=OpenAIEmbeddings(),\n",
        "    index=faiss.IndexFlatL2(dimension_size),\n",
        "    docstore=InMemoryDocstore(),\n",
        ")"
      ],
      "metadata": {
        "id": "_KnB_EUq8b7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# langchain vector db init 방식 (2)\n",
        "faiss_vector_db = FAISS.from_documents(\n",
        "    documents=example_docs, embedding=OpenAIEmbeddings()\n",
        "    )"
      ],
      "metadata": {
        "id": "WZSoAQO696TI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# langchain vector db init 방식 (3)\n",
        "faiss_vector_db = FAISS.from_texts(\n",
        "    example_list_text,\n",
        "    embedding=OpenAIEmbeddings(),\n",
        "    metadatas=[{\"source\": \"page1\"}, {\"source\": \"page2\"}],\n",
        "    ids=[\"doc_id1\", \"doc_id2\"],\n",
        ")"
      ],
      "metadata": {
        "id": "47klugCu-xm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retriever"
      ],
      "metadata": {
        "id": "fjluu0U1_P_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "langchain Vectorstore기반 retriever 생성"
      ],
      "metadata": {
        "id": "ilebKacj_daR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = faiss_vector_db.as_retriever()"
      ],
      "metadata": {
        "id": "MiCHTBuw_RGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "as_retriever()\n",
        "\n",
        "## parameters\n",
        "- search_type : (similarity, mmr, similarity_score_threshold)\n",
        "    * search_kwargs : (k, score_threshold, fetch_k, lambda_mult, filter...)\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "VMbbMnjVlvzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"search_kwargs\": {\"k\": 3}}}\n",
        "query = ''\n",
        "docs = retriever.invoke(query, config=config)"
      ],
      "metadata": {
        "id": "Fp7NtudZxI2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response Generation"
      ],
      "metadata": {
        "id": "yr2gC3wRvxJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open AI LLM\n",
        "\n",
        "api_key=os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    temperature=0,\n",
        "    model_name=\"gpt-4o\",\n",
        "    openai_api_key=api_key\n",
        ")"
      ],
      "metadata": {
        "id": "qGoIDspXnWyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Answer the question based on the following context:\n",
        "# Context\n",
        "{context}\n",
        "\n",
        "# Question\n",
        "{question}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Qoj9TjYV3UO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "retrieval_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "IoZCYdTNwcMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = ''\n",
        "retrival_chain.invoke(query)"
      ],
      "metadata": {
        "id": "NOHBI0i84W0Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}